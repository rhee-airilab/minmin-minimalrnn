{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:16.843229Z",
     "start_time": "2017-12-08T01:54:16.042985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function, division, absolute_import\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:16.846179Z",
     "start_time": "2017-12-08T01:54:16.844496Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -fvr logdir processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:17.204987Z",
     "start_time": "2017-12-08T01:54:17.082265Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p logdir/train logdir/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:17.984096Z",
     "start_time": "2017-12-08T01:54:17.667034Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data \\\n",
    "  import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:18.667216Z",
     "start_time": "2017-12-08T01:54:18.338718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = read_data_sets('./mnist', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:18.920674Z",
     "start_time": "2017-12-08T01:54:18.912561Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_UNITS = 28\n",
    "NUM_HIDDEN_UNITS = 31\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:19.472718Z",
     "start_time": "2017-12-08T01:54:19.466349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loop_count = mnist.train.num_examples // BATCH_SIZE\n",
    "test_loop_count  = mnist.test.num_examples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:20.032646Z",
     "start_time": "2017-12-08T01:54:20.026079Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from minimalrnn import MinimalRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:20.749425Z",
     "start_time": "2017-12-08T01:54:20.715002Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs, labels):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        cell = MinimalRNNCell(NUM_HIDDEN_UNITS)\n",
    "        \n",
    "        sequence_length = [MAX_SEQ_LEN] * BATCH_SIZE\n",
    "        \n",
    "        last, states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            inputs,\n",
    "            sequence_length=sequence_length,\n",
    "            dtype=tf.float32)\n",
    "        rnn_output = last[:,MAX_SEQ_LEN-1,:]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        \n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels,\n",
    "            outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "            minimize(loss)\n",
    "            \n",
    "        preds      = tf.argmax(outputs, axis=1)\n",
    "        errors     = tf.count_nonzero(labels - preds)\n",
    "        accuracy   = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                        tf.cast(tf.size(preds), tf.float32)\n",
    "        \n",
    "        self.inputs   = inputs\n",
    "        self.labels   = labels\n",
    "        self.outputs  = outputs\n",
    "        self.loss     = loss\n",
    "        self.optimize = optimize\n",
    "        self.accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:22.150641Z",
     "start_time": "2017-12-08T01:54:21.594345Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs_ = tf.placeholder(tf.float32, [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS], name='inputs')\n",
    "labels_ = tf.placeholder(tf.int64, [BATCH_SIZE], name='labels')\n",
    "\n",
    "model   = MnistRnn(inputs_, labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:22.679621Z",
     "start_time": "2017-12-08T01:54:22.494655Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess   = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:23.192904Z",
     "start_time": "2017-12-08T01:54:23.147129Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(max_epochs, train_writer=None, test_writer=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for ep in range(max_epochs):\n",
    "        for i in range(train_loop_count):\n",
    "            offs = i * BATCH_SIZE\n",
    "            batch_input = mnist.train.images[offs:offs+BATCH_SIZE,:].reshape([BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS])\n",
    "            batch_label = mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "            _, loss, accuracy = sess.run(\n",
    "                [model.optimize, model.loss, model.accuracy],\n",
    "                 feed_dict = {\n",
    "                     model.inputs: batch_input,\n",
    "                     model.labels: batch_label })\n",
    "            step += 1\n",
    "            if train_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value = [\n",
    "                        tf.Summary.Value(tag='accuracy',simple_value=accuracy),\n",
    "                        tf.Summary.Value(tag='loss',simple_value=loss),\n",
    "                    ])\n",
    "                train_writer.add_summary(summary, global_step=step)\n",
    "            if step % 250 == 0:\n",
    "                print('[trn] ep {:d}, step {:d}, loss {:.5f}, accu {:.5f}'.format(\n",
    "                    ep + 1, step, loss, accuracy))\n",
    "                \n",
    "        test_accuracies = []\n",
    "        for i in range(test_loop_count):\n",
    "            offs = i * BATCH_SIZE\n",
    "            batch_input = mnist.train.images[offs:offs+BATCH_SIZE,:].reshape([BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS])\n",
    "            batch_label = mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "            accuracy, = sess.run([model.accuracy],\n",
    "                                 feed_dict = {\n",
    "                                     model.inputs: batch_input,\n",
    "                                     model.labels: batch_label})\n",
    "            test_accuracies.append(accuracy)\n",
    "            if test_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value = [\n",
    "                        tf.Summary.Value(tag='accuracy',simple_value=accuracy),\n",
    "                    ])\n",
    "                test_writer.add_summary(summary, global_step=step)\n",
    "            if i % 250 == 0:\n",
    "                print('[tst] ep {:d}, step {:d}, accu {:.5f}'.format(\n",
    "                    ep + 1, step, np.mean(test_accuracies)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:54:24.995623Z",
     "start_time": "2017-12-08T01:54:23.785953Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter('logdir/train', graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter('logdir/test', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:55:16.485246Z",
     "start_time": "2017-12-08T01:54:24.996870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 1.54996, accu 0.55469\n",
      "[tst] ep 1, step 429, accu 0.73438\n",
      "[trn] ep 2, step 500, loss 1.01230, accu 0.67188\n",
      "[trn] ep 2, step 750, loss 0.76973, accu 0.79688\n",
      "[tst] ep 2, step 858, accu 0.85156\n",
      "[trn] ep 3, step 1000, loss 0.50725, accu 0.88281\n",
      "[trn] ep 3, step 1250, loss 0.29238, accu 0.92188\n",
      "[tst] ep 3, step 1287, accu 0.86719\n",
      "[trn] ep 4, step 1500, loss 0.31982, accu 0.92969\n",
      "[tst] ep 4, step 1716, accu 0.92188\n",
      "[trn] ep 5, step 1750, loss 0.26475, accu 0.91406\n",
      "[trn] ep 5, step 2000, loss 0.44737, accu 0.87500\n",
      "[tst] ep 5, step 2145, accu 0.93750\n",
      "[trn] ep 6, step 2250, loss 0.30873, accu 0.92969\n",
      "[trn] ep 6, step 2500, loss 0.46161, accu 0.83594\n",
      "[tst] ep 6, step 2574, accu 0.94531\n",
      "[trn] ep 7, step 2750, loss 0.27201, accu 0.92188\n",
      "[trn] ep 7, step 3000, loss 0.22683, accu 0.92188\n",
      "[tst] ep 7, step 3003, accu 0.96094\n",
      "[trn] ep 8, step 3250, loss 0.16873, accu 0.94531\n",
      "[tst] ep 8, step 3432, accu 0.96875\n",
      "[trn] ep 9, step 3500, loss 0.12490, accu 0.97656\n",
      "[trn] ep 9, step 3750, loss 0.16154, accu 0.95312\n",
      "[tst] ep 9, step 3861, accu 0.96875\n",
      "[trn] ep 10, step 4000, loss 0.21866, accu 0.93750\n",
      "[trn] ep 10, step 4250, loss 0.12697, accu 0.96094\n",
      "[tst] ep 10, step 4290, accu 0.98438\n"
     ]
    }
   ],
   "source": [
    "# tf.get_default_graph().finalize()\n",
    "train(10, train_writer, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:55:44.802841Z",
     "start_time": "2017-12-08T01:55:21.417390Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 0.4.0rc3 at http://rhee:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:55:47.657379Z",
     "start_time": "2017-12-08T01:55:47.540867Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:55:48.291321Z",
     "start_time": "2017-12-08T01:55:48.281415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing processed/label.txt\n"
     ]
    }
   ],
   "source": [
    "%%file processed/label.txt\n",
    "[0:Zero]\n",
    "[1:One]\n",
    "[2:Two]\n",
    "[3:Three]\n",
    "[4:Four]\n",
    "[5:Five]\n",
    "[6:Six]\n",
    "[7:Seven]\n",
    "[8:Eight]\n",
    "[9:Nine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:56:45.698137Z",
     "start_time": "2017-12-08T01:56:45.680191Z"
    }
   },
   "outputs": [],
   "source": [
    "t_vars = {v.name:v for v in tf.trainable_variables()}\n",
    "embedding_var = tf.Variable(t_vars[u'dense/kernel:0'].eval().transpose(), name='embedding')\n",
    "embedding_var.initializer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:56:50.671612Z",
     "start_time": "2017-12-08T01:56:50.669723Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:57:03.297587Z",
     "start_time": "2017-12-08T01:57:02.967132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./processed/save'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "embedding.metadata_path = './label.txt'\n",
    "\n",
    "summary_writer = tf.summary.FileWriter('./processed')\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "saver = tf.train.Saver([embedding_var])\n",
    "saver.save(sess, './processed/save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T01:57:20.989417Z",
     "start_time": "2017-12-08T01:57:06.796536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 0.4.0rc3 at http://rhee:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --logdir processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
